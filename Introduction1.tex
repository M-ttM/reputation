\documentclass[11pt,reqno]{amsart}
\usepackage[samelinetheorem,notitle]{maherart}
\usepackage{epigraph}

\usepackage{cancel}
\usepackage{mathrsfs}  
\usepackage{tikz}
\usetikzlibrary{arrows,positioning}
\usetikzlibrary{fit,shapes.geometric}
\usepackage{standalone}

\hypersetup{
    pdftitle =
        {Compromising Quality to Improve Reputation},
    pdfauthor =
        {Rahul Deb, Matthew Mitchell and Mallesh M. Pai},
    pdfsubject=
        {dynamic mechanism design, expert advice, bad reputation, bandits}
}

\begin{document}

\title[Our distrust is very expensive]{Our distrust is very expensive}

\author[Deb]{Rahul Deb$^{\between}$}
\address{$^{\between}$Department of Economics, University of Toronto\\\href{mailto:rahul.deb@utoronto.ca}{rahul.deb@utoronto.ca}}
\author[Mitchell]{Matthew Mitchell$^{\dagger}$}
\address{$^{\dagger}$Rotman Business School, University of Toronto\\\href{mailto:matthew.mitchell@rotman.utoronto.ca}{matthew.mitchell@rotman.utoronto.ca}}
\author[Pai]{Mallesh M. Pai$^{\ddag}$\\\today}
\address{$^{\ddag}$Department of Economics, Rice University\\\href{mailto:mallesh.pai@rice.edu}{mallesh.pai@rice.edu}}


\thanks{We would like to thank Heski Bar-Isaac, Dirk Bergemann, Jernej Copic, Martin Cripps, Joyee Deb, Mehmet Ekmekci, Drew Fudenberg, Marina Halac, Johannes H\"orner, Matt Jackson, Thomas Mariotti, Maher Said, Colin Stewart, Juuso V\"alim\"aki, Alex Wolitzky and audiences at numerous seminars for their time and insightful comments. Deb would like to thank Boston University, the Einaudi Institute and MIT for their hospitality and the SSHRC for their continued and generous financial support. Most of all, we would like to thank the fans. We really do it all for you...}

\begin{abstract}
Motivated by markets for expertise, we study a bandit model where a principal chooses between a safe and risky arm; the latter's type is known and its output is controlled by a strategic agent. Experimentation is potentially valuable only with the high type arm whereas, irrespective of type, the agent wants to maximize the duration of experimentation. We show that reputational concerns lead to inefficient output choices in all equilibria (subject to a mild refinement) and that, despite infinitesimal type uncertainty, market breakdown can occur. We discuss the implications for, and suggest ways to improve the functioning of, these markets.
\\
\\
\noindent
\textsc{Keywords:} reputation, repeated games of imperfect public monitoring, relational contracting, markets for expertise, media.
\\
\\
\noindent
\textsc{JEL Classification:}
D82, % Asymmetric and Private Information - Mechanism Design
D83, % Search - Learning - Information and Knowledge - Communication - Belief - Unawareness
D86. % Economics of Contract: Theory
\end{abstract}



\maketitle

\section{Introduction}\label{sec:intro}

Attention is money for much of the modern, advertising driven Internet. Typically, consumers do not pay for content and instead revenue is generated by their continued attention in the form of clicks. A consequence is that content providers need to sustain interest as consumers can withdraw their attention at any time. This creates a dilemma: since genuine content (which varies in quality) can only be generated periodically, how do content providers balance the quality and the frequency of the new content they provide with the aim of retaining interest? Specifically, how do they manage reputation in an environment where ``fake'' content can be generated at will? How does this revenue model (as opposed to traditional payment by subscription) affect market functioning?

Although it is a very different context, a similar incentives are also faced by ``experts'' employed in organizations. Specifically, consider a scientist working at a pharmaceutical company. The scientist's ability determines the frequency at which she receives research ideas that may ultimately lead to new products after successful drug trials. Even a talented scientist under pressure to keep his job could choose to recommend a drug trial for a new compound which is very unlikely to succeed but may help create the impression that he is generating new ideas. How does the company's decision of when to fire the scientist and their bonus structure (for successful trials) balance their incentives to give a talented scientist a sufficient amount of time to succeed (and reveal himself to be of high ability) but also prevent costly failed trials?

What is common to these (and numerous other) seemingly disparate examples is that they are environments in which a principal wants to dynamically screen an agent whose type (good or bad) determines the \emph{rate} at which she receives information that is payoff relevant for the principal and who acts based on this information in an effort to manage his \textit{reputation}. We a develop and study a novel repeated game to analyze such environments. Our main insight is that reputational incentives can be exceedingly strong in such environments: the need to establish reputation forces the agent to act inefficiently in every equilibrium (subject to a mild refinement) which in turn can result in large surplus losses due to market breakdown even when the principal knows that the agent is almost surely the good type.

Our framework is perhaps easiest to describe as a \textit{bandit model with a strategic arm} and we use this metaphor throughout the paper. In each period, the principal chooses between experimenting (visiting the website, extending employment) with a costly risky arm of unknown type and a costless safe arm. The arm's type is privately known by the agent who also controls its output. If the arm is the good type, it receives private information (news stories, research ideas) of varying quality (the accuracy of reporting, the scientific basis for efficacy of the compound) at a Poisson rate; the bad type never receives any information. If the principal decides to experiment, the agent chooses whether or not to public act (publish a story, run a drug trial) based on the received information (if any), and acting in turn generates a public success or failure (the veracity of the story once cross checked by other news outlets, the outcome of the drug trial), the probability of which depends on the quality of information. Acting based on high (low) quality information always (sometimes) results in a success; acting without information always generates a failure. The principal wants to simultaneously maximize and minimize the number of successes (true stories, successful drug trials) and failures respectively whereas the agent wants to maximize the duration of experimentation by the principal (number of website visits, period of employment).

Since actions are costless to the agent, there are no frictions in our environment if the agent is publicly known to the good type. In this ``first-best'' benchmark (\cref{thm:first_best}), the principal-optimal Nash equilibrium strategy is for her to always experiment and, in response, the good type agent (who is indifferent between all strategies) acts efficiently, that is, only when he receives high quality information. To make the model interesting, we assume that acting on low quality (and, by definition, without) information is inefficient in that it generates a negative expected payoff for the principal. This Nash equilibrium is also the unique Pareto-efficient outcome. Conversely, if the agent is known to be the bad type, there is a unique Nash equilibrium outcome in which the principal never experiments. This is because experimentation is costly and the bad type can never generate positive payoffs for the principal.

Despite the lack of frictions, there are a multiplicity of Nash equilibria even when the agent is known to be the good type. Indeed, there is a Nash equilibrium in which there is complete market breakdown: the agent's strategy is to never act and, in response, the principal never experiments. We view such inefficient equilibria to be unrealistic as they do not survive even the weakest notions of renegotiation proofness. Thus, our main focus is on equilibria (referred to as such without the ``Nash'' qualifier) of the repeated game in which we impose a refinement which rules out these, and only these, types of Nash equilibria. Specifically, our refinement requires that both players play the efficient or first-best strategies at all on-path histories where the principal's belief assigns probability one to the agent being the good type. We have previously referred to this refinement as ``mild'' since it only restricts on-path equilibrium strategies at one belief in contrast to standard, noncontroversial refinements such as Markov perfection.

When there is type uncertainty, the principal experiments in order to give the agent a chance to reveal himself as the good type by generating a success. Of course, whether or not experimentation is worthwhile depends on how many failures the principal must suffer along the way. To make this tradeoff between the agent's action strategy and the principal's decision to experiment explicit, we consider a second ``static'' benchmark. Here, the principal experiments for a single period and stops experimenting if no success is generated; conversely, if a success is generated then the refinement bites and the first-best continuation play results. Since only a success guarantees positive continuation value, the good type strictly best responds by acting on both high and low quality information; being indifferent, we assume he does not act in the absence of information. The sign of the principal's payoff in this benchmark determines her tolerance for a lack of quality control. When positive, these strategies constitute an equilibrium and, hence, the principal is willing to experiment even when the good type agent always acts on low-quality information.\footnote{The bad type must also act with positive probability as otherwise acting alone will cause the principal's belief to jump to one and so she will continue to experiment even after a failure. However, because our refinement only bites at belief one, this probability can be taken to be arbitrarily small so that the principal's loss from the bad type is correspondingly small.} Conversely, when the payoff in this benchmark is negative, \textit{quality control is necessary} for experimentation; in our applications, this corresponds to an unwillingness to visit a website with a consistently low standard of reporting or hiring a scientist who is always willing to conduct speculative drug trials. In this case, the principal has to provide long run incentives to police the agent's actions in order to generate a positive average value from experimentation \textbf{(show this formally)}.

In our first result, we show that the principal can never completely prevent the agent from choosing inefficient actions in any equilibrium (\cref{thm:no_commitment}). Specifically, in every equilibrium where the principal experiments, there are on-path histories where the agent acts both on low-quality information and in the absence of any information. Our main result (\cref{thm:breakdown}) shows that the loss of surplus from this can be large. Specifically, we show that, whenever quality control is necessary for experimentation, there is a unique equilibrium outcome in which the principal never experiments. This result shows that, whenever the principal needs to discipline the agent to make experimentation worthwhile, the agent's need to establish reputation makes this impossible.

What makes our result stark is that breakdown can occur even with arbitrarily small amounts of uncertainty or even if ``minimal'' quality control can make experimentation profitable. We discuss each of these and their implications in turn. First, observe that there are parameter values such that, if the agent always acts on low-quality information, the principal will not choose to experiment even when the agent is almost surely known to be the good type. For instance, this can occur if failures are very costly to the principal. An implication of our main result is that, in these cases, the principal's equilibrium payoff discontinuously drops from that of the first-best to zero as there is infinitesimal uncertainty about whether the agent is the good type. Returning to our first application, this implies that even a small amount of doubt in the veracity of a content provider (like a news source) can have a large impact for consumers. Specifically, the incentives that drive market breakdown in our model mirror the oft-cited criticism of the news media: the need to constantly generate new content drives down the quality of reporting in turn engendering public mistrust which contributes to the environment of dwindling web traffic.

When the principal's payoff in the static benchmark is negative but small, this corresponds to the case where the principal would not experiment if the agent acts inefficiently at every opportunity but she would experiment if the agent chose to behave efficiently even a small fraction of the time. Our result implies that the principal cannot even provide the long run incentives to make efficient play occur at a small fraction of histories. In this sense, the loss of surplus due to reputational concerns can be large relative to the first best.

We then examine the robustness of this main insight to changes in our modeling assumptions. We first show that introducing one-sided transfers---the principal can make a payment to the agent after the outcome from the agent's action is observed---does not change the result. This further generalizes our main insight to applications (such as our second example) where such transfers might occur. This result suggests that bonuses cannot correct an expert's strong reputational incentive to speculatively act as opposed to candidly admitting that they may not have any good ideas. We then show that the result is also not affected by making the information storable; here, the agent can choose to act on any information he has received in the past that he has not previously acted on. \textbf{Check this.}

How then can the functioning of such markets be improved? We argue that a natural way in which market breakdown can be avoided is if the principal can commit to a longer duration of experimentation: say $T>1$ periods at a time. For our two highlighted applications, this would amount to getting a subscription for online content or providing the expert with a fixed contract length respectively and only reevaluating the decision to continue experimentation after this fixed period expires. In the language of our model, this would amount to altering the stage game so that after the principal decides to experiment, the agent sequentially receives information and makes action choices $T$ times (with the cost of experimentation appropriately adjusted so we can make an apples-to-apples comparison). We argue that this commitment to longer experimentation can weaken the agent's need to immediately establish reputation which in turn can make experimentation profitable in cases where it would not have been if $T=1$. Thus, our model provides one rationale for why subscriptions might be a more efficient way to pay for online content and why longer contracts might reduce the amount of bad advice provided by experts in an attempt to prove their worth.

Finally, we explicitly highlight the role played by our refinement by showing that our main insights do not hold if it is dropped. Specifically, we construct Nash equilibria where the agent chooses efficient actions on path (\cref{thm:nash_eq}). Moreover, we argue that the discontinuity of payoffs at belief one disappears: as the uncertainty about the agent's type vanishes, there are Nash equilibria such that the payoffs to both players converge to the first-best. These equilibria (necessarily) have the unrealistic feature that there are on-path histories where the market breaks down even though incentives are perfectly aligned as the agent has revealed himself to be the good type with probability one.

\subsection{Related Literature}\label{sec:rel_lit}

Our paper is most closely related to the literature on reputation in repeated games. In a sentence, what separates our paper from the remaining literature is that we consider a model with two-long lived players (one of whom has multiple strategic types) and that we can make robust equilibrium predictions without requiring either player to be arbitrarily patient. With that said, we now discuss specific differences with the closest related papers.

Perhaps the closest work in the reputation literature is \cite{ely2003} (in particular, the refinement we impose is taken from their work). They also consider a two player repeated game and establish a ``bad reputation'' result where the reputational incentives of a long lived agent with a privately known type causes the loss of all surplus when faced with a sequence of short-lived principals. At a superficial level, our model differs because our game does not have the payoff structure of a bad reputation game (in the sense of \cite{ely2008}) and, additionally, our market breakdown result does not require the discount factor to approach one. More importantly, the forces that prevent the market from functioning are very different; because the principals are short lived in their setting, they do not internalize the future value that is gained from experimentation. Indeed, they show that their bad reputation result does not hold if both players are long lived.

This is also one of the differences between our model and that of \citet{bar-isaac2003} who similarly studies a signaling framework where, in his case, a seller of privately known quality can choose whether or not to sell a good in each period to a sequence of short-lived buyers. Like our model, the seller's quality determines the likelihood with which the good is publicly revealed to be a success or failure. Perhaps the most critical distinctions are that (i) we have additional private information that the agent receives periodically, and (ii) we aim to isolate a robust properties of all equilibria. He conversely shows that there exists a Markov perfect equilibrium that delivers his positive result.

There is a comparatively smaller fraction of the reputation literature that analyzes repeated games with two long-lived equally patient players. An early example is \cite{cripps1997}, more recent papers are \cite{atakan2012,atakan2013}. These papers have fundamentally different goals in that they aim to establish when reputation can be achieved (in the sense that the player with the unknown type can attain the Stackelberg payoff) as players become arbitrarily patient. We, by contrast, are interested in analyzing robust equilibrium outcomes for impatient players. We can do so because we analyze a very specific game; the above mentioned papers work with more general classes of games (to the best of knowledge, the game we study does not lie in the class of any paper in this strand of the literature). Framed this way, our paper can also be thought of as an instance of a relational contracting problem; perhaps the closest related recent papers are \cite{li2017} and \cite{mitchell2017} who analyze relational contracting models without transfers. The environment, applications and focus of these papers are quite distinct from ours.

While otherwise very different, the reputational incentives (and the fact that they can distort behavior) in our setting are similar in spirit to those in models where experts with private types attempt to appear competent (\cite{prendergast1996}, \cite{morris2001}, \cite{ottaviani2006reputational}). More recently, \citet{backus2018} consider a single period, extensive-form game of expert advise where they derive conditions under which an expert can admit uncertainty. Our setting shares an essential modeling feature that good types may not be able to provide the principal with positive utility in all periods.

Finally, our paper is related to a few papers in the literature on dynamic mechanism design which analyze outcomes both with and without commitment. \cite{guo2016} studies a dynamic setting without transfers where an agent is privately informed about the quality of a risky arm and she prefers greater experimentation than the principal (both prefer the risky arm only when it is good). While our setting differs substantially in terms of the payoff structure (and, hence the application to which we speak), the biggest difference is that the agent in our environment strategically acts in response to additional private information she receives over time. \cite{aghion2016} also look at a setting without transfers where a principal is trying to determine the type of a long-lived agent. While some features of our game are similar (the agent's payoff and the fact that she receives private information in each period), the main driving forces in their model are different. Specifically, signaling is not a source  of inefficiency in their setting; instead, the principal wants to the agent to take ``risky'' actions that are potentially damaging to the latter's reputation.

\newpage

%\nocite{}
\bibliographystyle{econometrica}
\bibliography{FakeNewsRefs}


\end{document}